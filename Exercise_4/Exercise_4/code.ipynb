{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import svg.path # for some reason this gave me alot of issues when in jupyter lab\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import copy\n",
    "import csv\n",
    "\n",
    "from PIL import ImageOps\n",
    "from PIL import Image\n",
    "from tslearn.metrics import dtw "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###\n",
    "# read the .svg and .jpg files to get binarized images\n",
    "\n",
    "def get_path_box(path: svg.path):\n",
    "    xmin = float('inf')\n",
    "    ymin = float('inf')\n",
    "    xmax = float('-inf')\n",
    "    ymax = float('-inf')\n",
    "    for segment in path:\n",
    "        if isinstance(segment, svg.path.Line):\n",
    "            x1, y1 = segment.start.real, segment.start.imag\n",
    "            x2, y2 = segment.end.real, segment.end.imag\n",
    "            xmin = min(xmin, x1, x2)\n",
    "            ymin = min(ymin, y1, y2)\n",
    "            xmax = max(xmax, x1, x2)\n",
    "            ymax = max(ymax, y1, y2)\n",
    "        elif isinstance(segment, svg.path.QuadraticBezier):\n",
    "            x1, y1 = segment.start.real, segment.start.imag\n",
    "            x2, y2 = segment.control.real, segment.control.imag\n",
    "            x3, y3 = segment.end.real, segment.end.imag\n",
    "            xmin = min(xmin, x1, x2, x3)\n",
    "            ymin = min(ymin, y1, y2, y3)\n",
    "            xmax = max(xmax, x1, x2, x3)\n",
    "            ymax = max(ymax, y1, y2, y3)\n",
    "        elif isinstance(segment, svg.path.CubicBezier):\n",
    "            x1, y1 = segment.start.real, segment.start.imag\n",
    "            x2, y2 = segment.control1.real, segment.control1.imag\n",
    "            x3, y3 = segment.control2.real, segment.control2.imag\n",
    "            x4, y4 = segment.end.real, segment.end.imag\n",
    "            xmin = min(xmin, x1, x2, x3, x4)\n",
    "            ymin = min(ymin, y1, y2, y3, y4)\n",
    "            xmax = max(xmax, x1, x2, x3, x4)\n",
    "            ymax = max(ymax, y1, y2, y3, y4)\n",
    "    return xmin, ymin, xmax, ymax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_svg_file(filenumber):\n",
    "    # image_path = 'ground-truth/locations/' + str(filenumber) + '.svg'\n",
    "    image_path = \"E:/Uni_courses/Pattern Recognetion/Exercises/Exercise_3/Pattern-Recognition/Exercise_4/ground-truth/locations/\" + str(filenumber) + \".svg\"\n",
    "    with open(image_path, 'r') as f:\n",
    "        svg_data = f.read()\n",
    "    root = ET.fromstring(svg_data)\n",
    "    # Extract the path commands for each word\n",
    "    words = []\n",
    "    ids = []\n",
    "    for path in root.findall('.//{http://www.w3.org/2000/svg}path'):\n",
    "        commands = path.attrib['d']\n",
    "        id = path.attrib['id']\n",
    "        words.append(commands)\n",
    "        ids.append(id)\n",
    "    return words, ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_images_from_words(filenumber, words):\n",
    "    img = Image.open(\"E:/Uni_courses/Pattern Recognetion/Exercises/Exercise_3/Pattern-Recognition/Exercise_4/images/\" + str(filenumber) + \".jpg\")\n",
    "    # Extract the word polygons and images\n",
    "    word_polygons = []\n",
    "    word_images = []\n",
    "    word_id = []\n",
    "    for i, word in enumerate(words):\n",
    "        path = svg.path.parse_path(word)\n",
    "        # Get the bounding box coordinates for the word\n",
    "        # I tried to find a built-in function but did not find it, so I implemented manually\n",
    "        xmin, ymin, xmax, ymax = get_path_box(path=path)\n",
    "        # Crop the image for the word\n",
    "        word_img = img.crop((xmin, ymin, xmax, ymax))\n",
    "        word_arr = np.array(word_img)\n",
    "        word_polygons.append(path)\n",
    "        word_images.append(word_arr)\n",
    "    return word_polygons, word_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_binarized_images(word_images):\n",
    "    # Binarization\n",
    "    binarized_word_images = []\n",
    "    for word_img in word_images:\n",
    "        #normalize to a consistant image size \n",
    "        target_size = (120, 90)\n",
    "        word_img = cv2.resize(word_img, target_size)\n",
    "        # Convert the image to grayscale\n",
    "        word_img_gray = ImageOps.grayscale(Image.fromarray(word_img))\n",
    "        # Adjust this threshold value as needed\n",
    "        threshold = 128  \n",
    "        word_img_bw = ImageOps.invert(word_img_gray).point(lambda x: 0 if x < threshold else 255, '1')\n",
    "        binarized_word_images.append(np.array(word_img_bw))\n",
    "    return binarized_word_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###\n",
    "# use sliding window to create feature matrices\n",
    "\n",
    "def fraction_of_black_pixels(window : np.array) -> float:\n",
    "    # gets the proportion of black vs white pixels\n",
    "    temp_window = window.flatten()\n",
    "    return temp_window.sum()/temp_window.shape[0]\n",
    "\n",
    "def upper_conture_location(window : np.array) -> int:\n",
    "    #finds the highest black pixel in the window\n",
    "    pos = window.shape[0] - 1\n",
    "    while(pos > 0):\n",
    "        if(window[pos].any()):\n",
    "            break\n",
    "        pos -= 1\n",
    "    return pos\n",
    "\n",
    "def lower_conture_location(window : np.array) -> int:\n",
    "    #finds the lowest black pixel in the window\n",
    "    pos = 0\n",
    "    while(pos < window.shape[0]):\n",
    "        if(window[pos].any()):\n",
    "            break\n",
    "        pos += 1\n",
    "    return pos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fraction_of_black_pixels_between_contures(window : np.array, lower_conture, upper_conture) -> float:\n",
    "    if lower_conture > upper_conture:# if there was no black pixel\n",
    "        return 0.0\n",
    "    elif lower_conture == upper_conture:# if there was only one black pixel\n",
    "        return 1 / window.shape[0]*window.shape[1]\n",
    "    else:\n",
    "        return fraction_of_black_pixels(window[lower_conture : upper_conture])\n",
    "\n",
    "def num_of_transitions(window : np.array, lower_conture : int, upper_conture : int) -> int:\n",
    "    # traverse down the middle of the window and count the number of times there is a change from black to white or white to black\n",
    "    if (lower_conture > upper_conture): # in case the window is empty\n",
    "        return 0\n",
    "    else:\n",
    "        y_axis = window.shape[1]//2\n",
    "        pos = 0\n",
    "        transistions = 0\n",
    "        last_point = window[pos,y_axis]\n",
    "        while(pos < window.shape[0]):\n",
    "            cur_point = window[pos,y_axis]\n",
    "            if(last_point != cur_point):\n",
    "                transistions += 1\n",
    "            last_point = cur_point\n",
    "            pos += 1\n",
    "        return transistions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sliding_window(input_image : np.array, window_length : int, window_off_set : int) -> np.array:\n",
    "    # creates a feature matrix using a sliding window\n",
    "    pos1 = 0  \n",
    "    pos2 = window_length\n",
    "    #print(input_image.shape)\n",
    "    out_windows = []\n",
    "    while(pos2 < input_image.shape[1]):\n",
    "        temp_window = input_image[:, pos1 : pos2]\n",
    "        feature_window = []\n",
    "        upper_conture = upper_conture_location(temp_window)\n",
    "        feature_window.append(upper_conture)\n",
    "        lower_conture = lower_conture_location(temp_window)\n",
    "        feature_window.append(lower_conture)\n",
    "        feature_window.append(fraction_of_black_pixels(temp_window))\n",
    "        feature_window.append(fraction_of_black_pixels_between_contures(temp_window, lower_conture, upper_conture))\n",
    "        feature_window.append(num_of_transitions(temp_window, lower_conture, upper_conture))\n",
    "        pos1 = (pos2 + window_off_set)\n",
    "        pos2 += (window_length + window_off_set)\n",
    "        out_windows.append(feature_window)\n",
    "    return np.array(out_windows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def feature_matrices(binarized_word_images : np.array) -> np.array:\n",
    "    feature_matrices = []\n",
    "    for pic in binarized_word_images:\n",
    "        feature_matrices.append(sliding_window(pic, 1, 1))\n",
    "    return feature_matrices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###\n",
    "# Get Feature Matrices for Train and Validation Sets\n",
    "\n",
    "def get_feature_matrices_train_set(train_files):\n",
    "    train_set_feature_matrices = []\n",
    "    ids = []\n",
    "\n",
    "    for train_file in train_files:\n",
    "        words, id = read_svg_file(train_file)\n",
    "        word_polygons, word_images = get_images_from_words(train_file, words)\n",
    "        binarized_word_images = get_binarized_images(word_images)\n",
    "        train_set_feature_matrices.append(feature_matrices(binarized_word_images))\n",
    "        ids.append(id)\n",
    "\n",
    "    train_set_flat = list(itertools.chain.from_iterable(train_set_feature_matrices))\n",
    "    train_ids_flat = list(itertools.chain.from_iterable(ids))\n",
    "    return train_set_flat, train_ids_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_feature_matrices_validation_set(validation_files):\n",
    "    validation_set_feature_matrices = []\n",
    "    ids = []\n",
    "\n",
    "    for validation_file in validation_files:\n",
    "        words, id = read_svg_file(validation_file)\n",
    "        word_polygons, word_images = get_images_from_words(validation_file, words)\n",
    "        binarized_word_images = get_binarized_images(word_images)\n",
    "        validation_set_feature_matrices.append(feature_matrices(binarized_word_images))\n",
    "        ids.append(id)\n",
    "\n",
    "    validation_set_flat = list(itertools.chain.from_iterable(validation_set_feature_matrices))\n",
    "    validation_ids_flat = list(itertools.chain.from_iterable(ids))\n",
    "    return validation_set_flat, validation_ids_flat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# This function calculates the DTW distance between each word in the validation set and the train set.\n",
    "def find_dtw(validation_set, train_set):\n",
    "    dtw_matrix = np.zeros(shape = (len(train_set), len(validation_set)))\n",
    "    for i in range(0 , len(train_set)):\n",
    "        for j in range(0, len(validation_set)):\n",
    "            dtw_matrix[i, j] = dtw(train_set[i], validation_set[j], global_constraint=\"sakoe_chiba\")\n",
    "    return dtw_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def print_word(id):\n",
    "    image_number = id.split('-')[0]\n",
    "    words, ids = read_svg_file(image_number)\n",
    "    idx = None\n",
    "    for index, string in enumerate(ids):\n",
    "        if string == id:\n",
    "            idx = index\n",
    "            break\n",
    "    word = words[idx]\n",
    "    path = svg.path.parse_path(word)\n",
    "    xmin, ymin, xmax, ymax = get_path_box(path=path)\n",
    "    img = Image.open('images/' + str(image_number) + '.jpg')\n",
    "    word_img = img.crop((xmin, ymin, xmax, ymax))\n",
    "    return(word_img.show())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_dtw_distances(dtw_distances):\n",
    "    ranked_dtw_distances = np.argsort(dtw_distances, axis = 1)\n",
    "    return ranked_dtw_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_transcription(train_files, validation_files):\n",
    "    f = open(\"E:/Uni_courses/Pattern Recognetion/Exercises/Exercise_3/Pattern-Recognition/Exercise_4/ground-truth/transcription.txt\", 'r')\n",
    "    Lines = f.readlines()\n",
    "    train_transcription = []\n",
    "    validation_transcription = []\n",
    "\n",
    "    for line in Lines:\n",
    "        file_number = int(line[0 : 3])\n",
    "\n",
    "        line = line.strip()\n",
    "        line = line[10:]\n",
    "\n",
    "        if file_number in train_files:\n",
    "            train_transcription.append(line)\n",
    "        else:\n",
    "            validation_transcription.append(line)\n",
    "\n",
    "    return train_transcription, validation_transcription\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def transfrom_rank_into_word(ranked_dtw_distances, train_transcription):\n",
    "    train_word_ranks = []\n",
    "\n",
    "    for validation_word_index in ranked_dtw_distances:\n",
    "        rank_per_word = []\n",
    "        for ranked_train_word_index in validation_word_index:\n",
    "            rank_per_word.append(train_transcription[ranked_train_word_index])\n",
    "\n",
    "        train_word_ranks.append(rank_per_word)\n",
    "\n",
    "    return train_word_ranks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_keywords():\n",
    "    f = open(\"E:/Uni_courses/Pattern Recognetion/Exercises/Exercise_3/Pattern-Recognition/Exercise_4/task/keywords.txt\", 'r')\n",
    "    Lines = f.readlines()\n",
    "\n",
    "    for i, line in enumerate(Lines):\n",
    "        line = line.strip()\n",
    "\n",
    "        Lines[i] = line\n",
    "\n",
    "    return Lines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_precision_and_recall(precision_top_ranks, keywords, ranked_train_words, validation_transcription):\n",
    "    precisions = [1]\n",
    "    recall = []\n",
    "\n",
    "    for precision in precision_top_ranks:\n",
    "        true_positive = 0\n",
    "        false_positive = 0\n",
    "        false_negative = 0\n",
    "        keywords_length = len(keywords)\n",
    "        for keyword in keywords:\n",
    "            if keyword in validation_transcription: # relevant elements, the ones we actually find in both the train and validation set\n",
    "                index = validation_transcription.index(keyword)\n",
    "                top_precision_words = ranked_train_words[index][:precision]\n",
    "                if (keyword in top_precision_words):\n",
    "                    true_positive += 1\n",
    "                    false_positive += precision - 1\n",
    "                else:\n",
    "                    false_positive += precision\n",
    "                    false_negative += 1\n",
    "            else:\n",
    "                keywords_length -= 1\n",
    "\n",
    "        if precision == precision_top_ranks[0]: # only print this once\n",
    "            print(\"Keywords actaully found in validation set: \" + str(keywords_length))\n",
    "            print(\"Number of total Keywords: \" + str(len(keywords)))\n",
    "\n",
    "        precisions.append(true_positive/(true_positive+false_positive))\n",
    "        recall.append(true_positive/(true_positive+false_negative))\n",
    "\n",
    "    recall.append(1)\n",
    "    return precisions, recall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def draw_precision_recall_curve(precision, recall):\n",
    "    plt.plot(recall, precision)\n",
    "    plt.title(\"Precision-Recall Curve\")\n",
    "    plt.xlabel(\"Recall\")\n",
    "    plt.ylabel(\"Precision\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_word_similarity = {\n",
    "    \"dtw\": 0,\n",
    "    \"word_id\": \"\"\n",
    "}\n",
    "\n",
    "training_word = {\n",
    "    \"transcription\": \"\",\n",
    "    \"similarities\": []\n",
    "}\n",
    "\n",
    "\n",
    "# This function calculates the DTW distance between each word in the validation set and the train set.\n",
    "def find_dtw_competition(validation_set, train_set, validation_ids, train_transcription):\n",
    "    # dtw_matrix = np.zeros(shape = (len(train_set), len(validation_set)))\n",
    "    dtw_matrix = []\n",
    "    for i in range(0 , len(train_set)):\n",
    "        train_word = copy.deepcopy(training_word)\n",
    "        train_word[\"transcription\"] = train_transcription[i]\n",
    "        temp_list = []\n",
    "        for j in range(0, len(validation_set)):\n",
    "            # dtw_matrix[i, j] = dtw(train_set[i], validation_set[j], global_constraint=\"sakoe_chiba\")\n",
    "            validation_word = copy.deepcopy(validation_word_similarity)\n",
    "            validation_word[\"dtw\"] = dtw(train_set[i], validation_set[j], global_constraint=\"sakoe_chiba\")\n",
    "            validation_word[\"word_id\"] = validation_ids[j]\n",
    "            temp_list.append(validation_word)\n",
    "        sorted_temp_list = sorted(temp_list, key=lambda x: x[\"dtw\"], reverse=True)\n",
    "        train_word[\"similarities\"] = copy.deepcopy(sorted_temp_list)\n",
    "        dtw_matrix.append(train_word)\n",
    "    return dtw_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_list_csv(input_list):\n",
    "    file_path = 'my_list_short.csv'  \n",
    "\n",
    "    # Open the CSV file in write mode\n",
    "    with open(file_path, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)  \n",
    "        writer.writerows(input_list)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# read the train and validation words and build feature matrices\n",
    "train_files = []\n",
    "validation_files = []\n",
    "train_files.extend(range(270, 280))\n",
    "validation_files.extend(range(300, 305))\n",
    "train_set, train_ids = get_feature_matrices_train_set(train_files)\n",
    "validation_set, validation_ids = get_feature_matrices_validation_set(validation_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate the DTW distances between each word in the validation set and the train set and rank them\n",
    "dtw_distances = find_dtw(validation_set, train_set)\n",
    "ranked_dtw_distances = rank_dtw_distances(dtw_distances)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transcription, validation_transcription = read_transcription(train_files, validation_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keywords actaully found in validation set: 98\n",
      "Number of total Keywords: 107\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Compare the ranked words for the keywords and calculate the precision\n",
    "train_transcription, validation_transcription = read_transcription(train_files, validation_files)\n",
    "ranked_train_words = transfrom_rank_into_word(ranked_dtw_distances, train_transcription)\n",
    "keywords = read_keywords()\n",
    "precision_top_ranks = np.arange(1, len(train_transcription))\n",
    "precision, recall = calculate_precision_and_recall(precision_top_ranks, keywords, ranked_train_words, validation_transcription)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtw_distances_competition = find_dtw_competition(validation_set, train_set, validation_ids, train_transcription)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtw_distances_competition = find_dtw_competition(validation_set, train_set, validation_ids, train_transcription)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "main_list = []\n",
    "for dict in dtw_distances_competition:\n",
    "    temp_list = []\n",
    "    temp_list.append(dict[\"transcription\"])\n",
    "    for i, word in enumerate(dict[\"similarities\"]):\n",
    "        if i < 50:\n",
    "            temp_list.append(word[\"word_id\"])\n",
    "            temp_list.append(word[\"dtw\"])\n",
    "        else:\n",
    "            break\n",
    "    main_list.append(copy.deepcopy(temp_list))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_list_csv(main_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "495"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dtw_distances_competition)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_precision_recall_curve(precision, recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtw_distances[15][25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked_dtw_distances[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
